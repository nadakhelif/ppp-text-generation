{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM/posCmrBG22y1nn7oGrj1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6d6618d68e1b42c3be1de2a2ac4bb045":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c607ad77f03451da4d13495fb005ff2","IPY_MODEL_95510f3d2c8b43b2a035a82bf17bf952","IPY_MODEL_de6600a6329041b39f2150b95d115d56"],"layout":"IPY_MODEL_37de7613411f42bc931e24c20e517871"}},"9c607ad77f03451da4d13495fb005ff2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c1fce22ac2c417f99cbb3ba3268be3c","placeholder":"​","style":"IPY_MODEL_f0507862daf2461d80ce383dd608f515","value":"Downloading (…)olve/main/vocab.json: 100%"}},"95510f3d2c8b43b2a035a82bf17bf952":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b5c4e71d9734f8cbee1bd4820554091","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18a8fb48df704c2ba69ad26f4683465d","value":1042301}},"de6600a6329041b39f2150b95d115d56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8252173aa2e4f0e86f705df511e6543","placeholder":"​","style":"IPY_MODEL_8e5e243362ff48188ff26fcb8f0630dd","value":" 1.04M/1.04M [00:00&lt;00:00, 7.58MB/s]"}},"37de7613411f42bc931e24c20e517871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c1fce22ac2c417f99cbb3ba3268be3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0507862daf2461d80ce383dd608f515":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b5c4e71d9734f8cbee1bd4820554091":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18a8fb48df704c2ba69ad26f4683465d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8252173aa2e4f0e86f705df511e6543":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e5e243362ff48188ff26fcb8f0630dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ba46420367f4e9b8aefcb881d456686":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69a07d4d16fb4f3b820679b5b9a7c6ce","IPY_MODEL_0ee5f420bd7d4b9489b85efe46a3e2b6","IPY_MODEL_9559ae02bcc14d8998846752f19011b6"],"layout":"IPY_MODEL_ef1298aa434b4876b8af26b32714817d"}},"69a07d4d16fb4f3b820679b5b9a7c6ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8ad3d380dc149ccb7f81aa7be8788bd","placeholder":"​","style":"IPY_MODEL_4c2d24880b7f4636a1da863214a9aa26","value":"Downloading (…)olve/main/merges.txt: 100%"}},"0ee5f420bd7d4b9489b85efe46a3e2b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04e741b3e6d24af3b5f527cb8628af51","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95ee8ddab28c47d8a17151e69dd4ac01","value":456318}},"9559ae02bcc14d8998846752f19011b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11304af2603543bd9996b4ded9b1bf1f","placeholder":"​","style":"IPY_MODEL_4c9a047e6288487381f7de52492c7a94","value":" 456k/456k [00:00&lt;00:00, 26.7MB/s]"}},"ef1298aa434b4876b8af26b32714817d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8ad3d380dc149ccb7f81aa7be8788bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c2d24880b7f4636a1da863214a9aa26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04e741b3e6d24af3b5f527cb8628af51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95ee8ddab28c47d8a17151e69dd4ac01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11304af2603543bd9996b4ded9b1bf1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c9a047e6288487381f7de52492c7a94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"067b123d553e49a390d2d9e2484ef94a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4cba4a4316eb41dcb5263c4e77926f63","IPY_MODEL_4904688f37834ffdac4f976501140eb5","IPY_MODEL_cd4498f46d704940a0a1081cec1f719e"],"layout":"IPY_MODEL_39f5e1f631004217abec25f594630d25"}},"4cba4a4316eb41dcb5263c4e77926f63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_233954dd2bba4890a28cbd63542e9cee","placeholder":"​","style":"IPY_MODEL_d80cf497dc064efb8c8ce39d113c0d03","value":"Downloading (…)lve/main/config.json: 100%"}},"4904688f37834ffdac4f976501140eb5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b8a47292766409b9bfff55b2cb1da35","max":666,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e5f6691cd4944549c740a7c03b93e13","value":666}},"cd4498f46d704940a0a1081cec1f719e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38de1920c448467a8b7213cf7e245e33","placeholder":"​","style":"IPY_MODEL_146aa62a6d254d72ac1f6c212c808580","value":" 666/666 [00:00&lt;00:00, 18.9kB/s]"}},"39f5e1f631004217abec25f594630d25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"233954dd2bba4890a28cbd63542e9cee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d80cf497dc064efb8c8ce39d113c0d03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b8a47292766409b9bfff55b2cb1da35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e5f6691cd4944549c740a7c03b93e13":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"38de1920c448467a8b7213cf7e245e33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"146aa62a6d254d72ac1f6c212c808580":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4315d288d94f4dc8b441c2e2ffe5854a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_333ae1ecba5b4e74bdd7c85de6371b7a","IPY_MODEL_91e63c966c7a4229997402845750bfd5","IPY_MODEL_154803bde1bd436699d38a75053900f6"],"layout":"IPY_MODEL_e18636bda49449d283df914b2ecea1c6"}},"333ae1ecba5b4e74bdd7c85de6371b7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b600b492d3824ff3bd42d5230eb39813","placeholder":"​","style":"IPY_MODEL_d56501d05d454f9392dbcf901ffebfb7","value":"Downloading tf_model.h5: 100%"}},"91e63c966c7a4229997402845750bfd5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8b175b6402f491aa6e391fcbe359550","max":3096618024,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4a7f0b23fee40b1a04091e3b9a3ee33","value":3096618024}},"154803bde1bd436699d38a75053900f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e9442d2351c47c2baf430d228a6ce1a","placeholder":"​","style":"IPY_MODEL_b17f64a3a2e74b73ac488684de6e5dde","value":" 3.10G/3.10G [01:18&lt;00:00, 50.9MB/s]"}},"e18636bda49449d283df914b2ecea1c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b600b492d3824ff3bd42d5230eb39813":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d56501d05d454f9392dbcf901ffebfb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8b175b6402f491aa6e391fcbe359550":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4a7f0b23fee40b1a04091e3b9a3ee33":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e9442d2351c47c2baf430d228a6ce1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b17f64a3a2e74b73ac488684de6e5dde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3babb54abef4e558b4f9d231186081c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01164f79c0234c529f6d2ac85896c4c9","IPY_MODEL_40ad8dc3e8e64cb9b2dc186bcc1ff09a","IPY_MODEL_eeb1f66b5a9e403d9845fe46e5202cb8"],"layout":"IPY_MODEL_e7f4d7b7af664209ae194fd7fa97e090"}},"01164f79c0234c529f6d2ac85896c4c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b0bdf594b30468389e65f309c37d7f6","placeholder":"​","style":"IPY_MODEL_816ed36325384e80aca323fc523a2a56","value":"Downloading (…)neration_config.json: 100%"}},"40ad8dc3e8e64cb9b2dc186bcc1ff09a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f027342bfc34b1782e1d80f9684ba2f","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2dbdf7f0f8d34dddad15f70435aff399","value":124}},"eeb1f66b5a9e403d9845fe46e5202cb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25117763b1ec4838ba2d5948d8d7f1e0","placeholder":"​","style":"IPY_MODEL_24b66c1c78384343afe9a7b21fc613b0","value":" 124/124 [00:00&lt;00:00, 1.93kB/s]"}},"e7f4d7b7af664209ae194fd7fa97e090":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b0bdf594b30468389e65f309c37d7f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"816ed36325384e80aca323fc523a2a56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f027342bfc34b1782e1d80f9684ba2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dbdf7f0f8d34dddad15f70435aff399":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25117763b1ec4838ba2d5948d8d7f1e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24b66c1c78384343afe9a7b21fc613b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-MBhTHlFbM9","executionInfo":{"status":"ok","timestamp":1682940806378,"user_tz":-120,"elapsed":22175,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"dc3cf4a7-6429-4921-f893-44c9d5152184"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["!pip install transformers\n"]},{"cell_type":"code","source":["#for reproducability\n","SEED = 34\n","\n","#maximum number of words in output text\n","MAX_LEN = 70\n","\n","input_sequence = \"I don't know about you, but there's only one thing I want to do after a long day of work\""],"metadata":{"id":"q9Y6Q1R0Fl7P","executionInfo":{"status":"ok","timestamp":1682940816999,"user_tz":-120,"elapsed":3,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#get transformers\n","from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n","\n","#get large GPT2 tokenizer and GPT2 model\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")\n","GPT2 = TFGPT2LMHeadModel.from_pretrained(\"gpt2-large\", pad_token_id=tokenizer.eos_token_id)\n","\n","#tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n","#GPT2 = TFGPT2LMHeadModel.from_pretrained(\"gpt2-medium\", pad_token_id=tokenizer.eos_token_id)\n","\n","#tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","#GPT2 = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n","\n","#view model parameters\n","GPT2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467,"referenced_widgets":["6d6618d68e1b42c3be1de2a2ac4bb045","9c607ad77f03451da4d13495fb005ff2","95510f3d2c8b43b2a035a82bf17bf952","de6600a6329041b39f2150b95d115d56","37de7613411f42bc931e24c20e517871","1c1fce22ac2c417f99cbb3ba3268be3c","f0507862daf2461d80ce383dd608f515","7b5c4e71d9734f8cbee1bd4820554091","18a8fb48df704c2ba69ad26f4683465d","b8252173aa2e4f0e86f705df511e6543","8e5e243362ff48188ff26fcb8f0630dd","5ba46420367f4e9b8aefcb881d456686","69a07d4d16fb4f3b820679b5b9a7c6ce","0ee5f420bd7d4b9489b85efe46a3e2b6","9559ae02bcc14d8998846752f19011b6","ef1298aa434b4876b8af26b32714817d","d8ad3d380dc149ccb7f81aa7be8788bd","4c2d24880b7f4636a1da863214a9aa26","04e741b3e6d24af3b5f527cb8628af51","95ee8ddab28c47d8a17151e69dd4ac01","11304af2603543bd9996b4ded9b1bf1f","4c9a047e6288487381f7de52492c7a94","067b123d553e49a390d2d9e2484ef94a","4cba4a4316eb41dcb5263c4e77926f63","4904688f37834ffdac4f976501140eb5","cd4498f46d704940a0a1081cec1f719e","39f5e1f631004217abec25f594630d25","233954dd2bba4890a28cbd63542e9cee","d80cf497dc064efb8c8ce39d113c0d03","6b8a47292766409b9bfff55b2cb1da35","7e5f6691cd4944549c740a7c03b93e13","38de1920c448467a8b7213cf7e245e33","146aa62a6d254d72ac1f6c212c808580","4315d288d94f4dc8b441c2e2ffe5854a","333ae1ecba5b4e74bdd7c85de6371b7a","91e63c966c7a4229997402845750bfd5","154803bde1bd436699d38a75053900f6","e18636bda49449d283df914b2ecea1c6","b600b492d3824ff3bd42d5230eb39813","d56501d05d454f9392dbcf901ffebfb7","c8b175b6402f491aa6e391fcbe359550","a4a7f0b23fee40b1a04091e3b9a3ee33","1e9442d2351c47c2baf430d228a6ce1a","b17f64a3a2e74b73ac488684de6e5dde","a3babb54abef4e558b4f9d231186081c","01164f79c0234c529f6d2ac85896c4c9","40ad8dc3e8e64cb9b2dc186bcc1ff09a","eeb1f66b5a9e403d9845fe46e5202cb8","e7f4d7b7af664209ae194fd7fa97e090","8b0bdf594b30468389e65f309c37d7f6","816ed36325384e80aca323fc523a2a56","5f027342bfc34b1782e1d80f9684ba2f","2dbdf7f0f8d34dddad15f70435aff399","25117763b1ec4838ba2d5948d8d7f1e0","24b66c1c78384343afe9a7b21fc613b0"]},"id":"vnTTEVxfFqX-","executionInfo":{"status":"ok","timestamp":1682940978252,"user_tz":-120,"elapsed":140226,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"d2cd4f98-faca-4846-e06d-915a7efaa949"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d6618d68e1b42c3be1de2a2ac4bb045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ba46420367f4e9b8aefcb881d456686"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"067b123d553e49a390d2d9e2484ef94a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tf_model.h5:   0%|          | 0.00/3.10G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4315d288d94f4dc8b441c2e2ffe5854a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n","\n","All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2-large.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3babb54abef4e558b4f9d231186081c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model: \"tfgpt2lm_head_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," transformer (TFGPT2MainLaye  multiple                 774030080 \n"," r)                                                              \n","                                                                 \n","=================================================================\n","Total params: 774,030,080\n","Trainable params: 774,030,080\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["**First Pass (Greedy Search)**\n","With Greedy search, the word with the highest probability is predicted as the next word i.e. the next word is updated via:\n","\n","wt=argmaxwP(w|w1:t−1)\n"," \n","at each timestep  t\n"," . Let's see how this naive approach performs:"],"metadata":{"id":"EDlQYSLcNiY4"}},{"cell_type":"code","source":["#get deep learning basics\n","import tensorflow as tf\n","tf.random.set_seed(SEED)"],"metadata":{"id":"I9hAaN8YF5dv","executionInfo":{"status":"ok","timestamp":1682940978253,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# encode context the generation is conditioned on\n","input_ids = tokenizer.encode(input_sequence, return_tensors='tf')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","greedy_output = GPT2.generate(input_ids, max_length = MAX_LEN)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(greedy_output[0], skip_special_tokens = True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7HucUu2F9c7","executionInfo":{"status":"ok","timestamp":1682941060849,"user_tz":-120,"elapsed":73801,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"3613ff71-06ea-44cb-ba65-3fcfdd001f84"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I don't know about you, but there's only one thing I want to do after a long day of work: go to the gym.\n","\n","I'm not talking about the gym that's right next to my house. I'm talking about the gym that's right next to my office.\n","\n","I'm not talking about the gym that\n"]}]},{"cell_type":"markdown","source":["**Beam Search** with N-Gram Penalities\n","Beam search is essentially Greedy Search but the model tracks and keeps num_beams of hypotheses at each time step, so the model is able to compare alternative paths as it generates text. We can also include a n-gram penalty by setting no_repeat_ngram_size = 2 which ensures that no 2-grams appear twice. We will also set num_return_sequences = 5 so we can see what the other 5 beams looked like\n","\n","To use Beam Search, we need only modify some parameters in the generate function"],"metadata":{"id":"FqJ-Z31RNUI0"}},{"cell_type":"code","source":["# set return_num_sequences > 1\n","beam_outputs = GPT2.generate(\n","    input_ids, \n","    max_length = MAX_LEN, \n","    num_beams = 5, \n","    no_repeat_ngram_size = 2, \n","    num_return_sequences = 5, \n","    early_stopping = True\n",")\n","\n","print('')\n","print(\"Output:\\n\" + 100 * '-')\n","\n","# now we have 3 output sequences\n","for i, beam_output in enumerate(beam_outputs):\n","      print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2JyZR1N5GBM5","executionInfo":{"status":"ok","timestamp":1682941251852,"user_tz":-120,"elapsed":143503,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"0170ee43-9231-48ac-995d-d96f09ebb85e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Output:\n","----------------------------------------------------------------------------------------------------\n","0: I don't know about you, but there's only one thing I want to do after a long day of work, and that's to sit down and watch a movie.\"\n","\n","\"I know, I know,\" you say. \"But you're not going to like this one. It's not a good movie. I mean, it's\n","1: I don't know about you, but there's only one thing I want to do after a long day of work, and that's to sit down and watch a movie.\"\n","\n","\"I know, I know,\" you say. \"But you're not going to like this one. It's about a guy who has a crush on a girl\n","2: I don't know about you, but there's only one thing I want to do after a long day of work, and that's to sit down and watch a movie.\"\n","\n","\"I know, I know,\" you say. \"But you're not going to like this one. It's about a guy who has a crush on a woman\n","3: I don't know about you, but there's only one thing I want to do after a long day of work, and that's to sit down and watch a movie.\"\n","\n","\"I know, I know,\" you say. \"But you're not going to like this one. It's about a guy who has a crush on a beautiful\n","4: I don't know about you, but there's only one thing I want to do after a long day of work, and that's to sit down and watch a movie.\"\n","\n","\"I know, I know,\" you say. \"But you're not going to like this one. It's not a good movie. I'm not sure if\n"]}]},{"cell_type":"markdown","source":["\n","**Basic Sampling** Now we will explore indeterministic decodings - sampling. Instead of following a strict path to find the end text with the highest probability, we instead randomly pick the next word by its conditional probability distribution:\n","\n","wt∼P(w|w1:t−1)\n"," \n","However, when we include this randomness, the generated text tends to be incoherent (see more here) so we can include the temperature parameter which increases the chances of high probability words and decreases the chances of low probability words in the sampling:\n","\n","We just need to set do_sample = True to implement sampling and for demonstration purposes (you'll shortly see why) we set top_k = 0:"],"metadata":{"id":"pDSAol98NzmO"}},{"cell_type":"code","source":["# use temperature to decrease the sensitivity to low probability candidates\n","sample_output = GPT2.generate(\n","                             input_ids, \n","                             do_sample = True, \n","                             max_length = MAX_LEN, \n","                             top_k = 0, \n","                             temperature = 0.8\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens = True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DN5x76caGC8g","executionInfo":{"status":"ok","timestamp":1682941609203,"user_tz":-120,"elapsed":60730,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"a826309b-f3c9-43e7-9371-0f1b83e776c1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I don't know about you, but there's only one thing I want to do after a long day of work.\"\n","\n","\"Hmm. Must be quite the choice of words.\"\n","\n","\"Well, it's not a choice of words, but a need. I can't find the right answer until I find my answer.\"\n","\n","\"\n"]}]},{"cell_type":"markdown","source":["**Top-K Sampling**\n","In Top-K sampling, the top k most likely next words are selected and the entire probability mass is shifted to these k words. So instead of increasing the chances of high probability words occuring and decreasing the chances of low probabillity words, we just remove low probability words all together\n","\n","We just need to set top_k to however many of the top words we want to consider for our conditional probability distribution:"],"metadata":{"id":"LOuS9PyKOQPR"}},{"cell_type":"code","source":["#sample from only top_k most likely words\n","sample_output = GPT2.generate(\n","                             input_ids, \n","                             do_sample = True, \n","                             max_length = MAX_LEN, \n","                             top_k = 50\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens = True), '...')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeM59nvzGJbB","executionInfo":{"status":"ok","timestamp":1682941669030,"user_tz":-120,"elapsed":59830,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"c4b696a9-b0a0-4123-9134-466a99ce92b8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I don't know about you, but there's only one thing I want to do after a long day of work. I want to get out of here and go jogging. To go jogging.\"\n","\n","\"That may be true, but I don't really have much money to spare!\"\n","\n","\"That's true too. Why don ...\n"]}]},{"cell_type":"markdown","source":["\n","**Top-P sampling** (also known as nucleus sampling) is similar to Top-K, but instead of choosing the top k most likely wordsm we choose the smallest set of words whose total probability is larger than p, and then the entire probability mass is shifted to the words in this set\n","\n","The main difference here is that with Top-K sampling, the size of the set of words is static (obviously) whereas in Top-P sampling, the size of the set can change. To use this sampling method, we just set top_k = 0 and choose a value top_p:"],"metadata":{"id":"bAHul1E6ObHx"}},{"cell_type":"code","source":["#sample only from 80% most likely words\n","sample_output = GPT2.generate(\n","                             input_ids, \n","                             do_sample = True, \n","                             max_length = MAX_LEN, \n","                             top_p = 0.8, \n","                             top_k = 0\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(sample_output[0], skip_special_tokens = True), '...')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHmVJ8g7GMYU","executionInfo":{"status":"ok","timestamp":1682941727257,"user_tz":-120,"elapsed":58237,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"3a253698-0f83-42e8-f206-ba6f0b6e86e6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","I don't know about you, but there's only one thing I want to do after a long day of work: try out some dessert! Today I've got a total of four different fruit ice creams from The Baker's Dozen. I'm going to share three of them with you, each with a twist.\n","\n","One was made ...\n"]}]},{"cell_type":"markdown","source":["**Top-K and Top-P Sampling**\n","As you could have probably guessed, we can use both Top-K and Top-P sampling here. This reduces the chances of us getting weird words (low probability words) while allowing for a dynamic selection size. We need only top a value for both top_k and top_p. We can even include the inital temperature parameter if we want to, Let's now see how our model performs now after adding everything together. We will check the top 5 return to see how diverse our answers are:"],"metadata":{"id":"uPYaRo1uOrlD"}},{"cell_type":"code","source":["#combine both sampling techniques\n","sample_outputs = GPT2.generate(\n","                              input_ids,\n","                              do_sample = True, \n","                              max_length = 2*MAX_LEN,                              #to test how long we can generate and it be coherent\n","                              #temperature = .7,\n","                              top_k = 50, \n","                              top_p = 0.85, \n","                              num_return_sequences = 5\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, sample_output in enumerate(sample_outputs):\n","    print(\"{}: {}...\".format(i, tokenizer.decode(sample_output, skip_special_tokens = True)))\n","    print('')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kl55DP4OGRZ5","executionInfo":{"status":"ok","timestamp":1682942056453,"user_tz":-120,"elapsed":329198,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"0f8d8d45-d4d6-4a55-c3d3-80a0bf5e04bc"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: I don't know about you, but there's only one thing I want to do after a long day of work and this is one of it. I have to do something else. It's been quite an exciting couple of weeks at the office, haven't I?\n","\n","Makes you wonder about the people who didn't get the memo that a long day of work is about to turn into a long day of fun....\n","\n","1: I don't know about you, but there's only one thing I want to do after a long day of work: watch some movies on my bed!\n","\n","So, I took a trip to my local mall to check out a new line of \"couples\" furniture. It's the same type of furniture that I saw on an episode of The Bachelor. It's the kind of furniture that makes me think that if I were to be on a reality TV show, I would be dating one of the characters from that show.\n","\n","The first thing I noticed about the furniture was that there are no chairs. There is only one bed, a desk, a table, and two chairs...\n","\n","2: I don't know about you, but there's only one thing I want to do after a long day of work, and that's to go on an adventure! You know, to see if I can get myself to the bottom of the hole before some kind of horrible death and/or injury happens to me. The one thing I know for sure is that I have never, ever, played in a hole of my own creation. I can say that from experience. The hole is my work. I had no choice but to use it as a playground. I used to do some of my most interesting and imaginative work on the hole.\n","\n","When I say \"my hole,\" I mean the...\n","\n","3: I don't know about you, but there's only one thing I want to do after a long day of work.\n","\n","\n","Oh, how my soul hurts to think of it.\n","\n","\n","The only reason I'm able to stand to look at myself in the mirror, with my face so distorted, is because I know it's not me.\n","\n","\n","I was a little sad to hear that a person would die in the car accident on the way to the hospital.\n","\n","\n","It's the only way to express how I feel when you don't say the right words at the right time.\n","\n","\n","I had the opportunity to visit some of the most amazing people in the world in New York...\n","\n","4: I don't know about you, but there's only one thing I want to do after a long day of work. I want to relax and watch TV and not worry about work.\n","\n","My first stop on my weekend road trip is the nearest shopping mall.\n","\n","We are on the way to my aunt's house. She's a retired teacher. I can't wait to spend my weekends with her.\n","\n","After walking to the mall, I walked around the city. I looked around the different shopping centers and shops. There's so much to do in Japan.\n","\n","I picked out a few shops to visit in this shopping mall.\n","\n","One of them was a souvenir...\n","\n"]}]},{"cell_type":"code","source":["MAX_LEN = 150\n","prompt1 = 'In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.'\n","\n","input_ids = tokenizer.encode(prompt1, return_tensors='tf')"],"metadata":{"id":"jx3I76fDGVGb","executionInfo":{"status":"ok","timestamp":1682942056454,"user_tz":-120,"elapsed":4,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["sample_outputs = GPT2.generate(\n","                              input_ids,\n","                              do_sample = True, \n","                              max_length = MAX_LEN,                              #to test how long we can generate and it be coherent\n","                              #temperature = .8,\n","                              top_k = 50, \n","                              top_p = 0.85 \n","                              #num_return_sequences = 5\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, sample_output in enumerate(sample_outputs):\n","    print(\"{}: {}...\".format(i, tokenizer.decode(sample_output, skip_special_tokens = True)))\n","    print('')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"446X3lNOGfil","executionInfo":{"status":"ok","timestamp":1682942188377,"user_tz":-120,"elapsed":131926,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"49243c59-2985-48be-a0cb-bdec1b5257bf"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n","\n","According to National Geographic, scientists from the University of São Paulo, Brazil, discovered that the unicorns lived in a valley in the remote Andes mountains, near the village of Mato Grosso do Sul, on the Atlantic coast. The researchers found a number of large horned and bearded animals. They also found traces of humans living nearby, and the animals also carried traces of blood from humans.\n","\n","The team found the unicorn herd and its human visitors in a valley where they had been watching a herd...\n","\n"]}]},{"cell_type":"code","source":["prompt2 = 'Miley Cyrus was caught shoplifting from Abercrombie and Fitch on Hollywood Boulevard today.'\n","\n","input_ids = tokenizer.encode(prompt2, return_tensors='tf')"],"metadata":{"id":"GaEJW4L0GgIW","executionInfo":{"status":"ok","timestamp":1682942188379,"user_tz":-120,"elapsed":16,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["sample_outputs = GPT2.generate(\n","                              input_ids,\n","                              do_sample = True, \n","                              max_length = MAX_LEN,                              #to test how long we can generate and it be coherent\n","                              #temperature = .8,\n","                              top_k = 50, \n","                              top_p = 0.85\n","                              #num_return_sequences = 5\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, sample_output in enumerate(sample_outputs):\n","    print(\"{}: {}...\".format(i, tokenizer.decode(sample_output, skip_special_tokens = True)))\n","    print('')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9N7lA3uGksA","executionInfo":{"status":"ok","timestamp":1682942351428,"user_tz":-120,"elapsed":163064,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"24fcf9b9-5c97-4efe-d3eb-df79ad328027"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: Miley Cyrus was caught shoplifting from Abercrombie and Fitch on Hollywood Boulevard today.\n","\n","The former Disney star, 22, was spotted leaving the store on her bicycle with $500 in cash.\n","\n","The news came on a day that Cyrus had been spotted in Beverly Hills with rapper Drake.\n","\n","The two had met earlier in the day for a photo shoot, which resulted in them meeting the public.\n","\n","Scroll down for video\n","\n","The former Disney star was caught shoplifting from Abercrombie & Fitch on Hollywood Boulevard today\n","\n","Cyrus was spotted leaving the store on her bicycle with $500 in cash\n","\n","Cyrus was seen wearing a yellow top and white shorts with a blue and white striped...\n","\n"]}]},{"cell_type":"code","source":["prompt3 = 'Legolas and Gimli advanced on the orcs, raising their weapons with a harrowing war cry.'\n","\n","input_ids = tokenizer.encode(prompt3, return_tensors='tf')"],"metadata":{"id":"pvqOgViWGnSZ","executionInfo":{"status":"ok","timestamp":1682942351429,"user_tz":-120,"elapsed":15,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["sample_outputs = GPT2.generate(\n","                              input_ids,\n","                              do_sample = True, \n","                              max_length = MAX_LEN,                              #to test how long we can generate and it be coherent\n","                              #temperature = .8,\n","                              top_k = 50, \n","                              top_p = 0.85 \n","                              #num_return_sequences = 5\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, sample_output in enumerate(sample_outputs):\n","    print(\"{}: {}...\".format(i, tokenizer.decode(sample_output, skip_special_tokens = True)))\n","    print('')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAvI-v1IGqZO","executionInfo":{"status":"ok","timestamp":1682942515617,"user_tz":-120,"elapsed":164202,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"bbab9f06-cfed-47b2-b4cb-4695fac6431b"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: Legolas and Gimli advanced on the orcs, raising their weapons with a harrowing war cry.\n","\n","All of the orc warbands, including the ones from which they were drawn, began charging, leaving the Alliance's ranks behind. The two sides battled with the orc warriors in close combat, and even though the two sides continued to clash, the battle seemed to go on forever. Then, all at once, the entire horde of orcs turned, as if to charge the approaching orcs. The battle began again, and the battle continued. The battle raged on for a good ten minutes or so, until the orcs were surrounded and routed. The battle continued on for another ten minutes or so, until all of the orcs were dead. All of the...\n","\n"]}]},{"cell_type":"code","source":["prompt4 = \"For today’s homework assignment, please describe the reasons for the US Civil War.\"\n","\n","input_ids = tokenizer.encode(prompt4, return_tensors='tf')"],"metadata":{"id":"BSMt2-ZBGwE-","executionInfo":{"status":"ok","timestamp":1682942515618,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["sample_outputs = GPT2.generate(\n","                              input_ids,\n","                              do_sample = True, \n","                              max_length = MAX_LEN,                              #to test how long we can generate and it be coherent\n","                              #temperature = .8,\n","                              top_k = 50, \n","                              top_p = 0.85 \n","                              #num_return_sequences = 5\n",")\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, sample_output in enumerate(sample_outputs):\n","    print(\"{}: {}...\".format(i, tokenizer.decode(sample_output, skip_special_tokens = True)))\n","    print('')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jluWrUXpGxQq","executionInfo":{"status":"ok","timestamp":1682942545852,"user_tz":-120,"elapsed":30238,"user":{"displayName":"Ahmed Frikha","userId":"11136541355280740406"}},"outputId":"8838636a-39db-423a-e453-95e8b9f1297d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Output:\n","----------------------------------------------------------------------------------------------------\n","0: For today’s homework assignment, please describe the reasons for the US Civil War.\n","\n","For more from The Week's Power Lunch, click here.\n","\n","Follow @dgbxny...\n","\n"]}]}]}